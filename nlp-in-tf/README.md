# Natural Language Processing in TensorFlow


## Topics to Learn

- Read what what is a Corpus
- Read about Tokenizer alternative tf.keras.layers.TextVectorization
- Finding a way to removing the common words from sentences such as "to, from, the, etc" because they don't have semantic, so it will be remove from word_index
- Read about csv package
- Read about TensorFlow Data Services - TFDF, which contains many available datasets (images, texts, audio)
- Learn how embedding work
- In NLP different Flatten layer used which is Global Average Pooling 1D
- Read about Embedding Layer https://www.tensorflow.org/text/guide/word_embeddings
- Read abour SubwordTextEncoder https://www.tensorflow.org/datasets/api_docs/python/tfds/deprecated/text/SubwordTextEncoder
- Read about tf.keras.layers.TextVectorization https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/keras/layers/TextVectorization
- Understand embedding dimension
- Read about tokenizer parameters num_words=n
- Read more about subword tokenization
- Read about RNN, GIU, LSTM
- Check Sequence Models course by Andrew https://www.coursera.org/lecture/nlp-sequence-models/deep-rnns-ehs0S
- Read about LSTM here https://www.coursera.org/lecture/n|p-sequence-models/long-short-term-memory-Istm-KXoay
- Read about LSTM in tensorflow https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM
- 